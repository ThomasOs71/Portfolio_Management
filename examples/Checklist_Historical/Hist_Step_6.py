# -*- coding: utf-8 -*-
"""
Created on Wed Dec  4 13:16:32 2024

@author: Thomas

Step 6: Ex-ante evaluation:

This case study performs Step 6 of the "Checklist", namely Ex-ante evaluation. 

The purpose of this step is:
    
    to measure the satisfaction of an ex-ante performance variable 

generated by a static allocation 
or a more general allocation policy, based on its distribution f_y.
 
Equivalently, we can measure the risk as the negative satisfaction. 
The desirable properties of satisfaction/risk measures and the most common measures 
are discussed extensively within Step 6.

Satisfaction measure:	
- Performance expectation	
- Performance (negative) variance	
- Certainty-equivalent with exponential utility	
- Quantile (negative VaR)	
- Sub-quantile (negative cVaR)	 
 
Here the performance variable is the portfolio linear return Y = T and 
we compute the satisfaction measures Satis{R}, given the 
scenario-probability distribution of the ex-ante performance 
obtained in s_checklist_historical_step05b.
"""

# %% Prepare environment
### Packages
from numpy import exp, log, append, diff, argsort, sum, cumsum, round, sqrt, abs
from scipy.stats import norm as normal
from pandas import read_csv, DataFrame, Series

### Load data
'''
From database db_forecast_historical created in script s_checklist_historical_step03b,
we upload:
    1) the scenario probabilities 
'''

db_forecast_historical = read_csv(r'C:\Projects\Portfolio_Management\examples\Checklist_Historical\Data\Input_Step4/db_forecast_historical.csv', low_memory=False)
p_j = db_forecast_historical.p_scenario.dropna()  # probabilities

'''
From database db_exante_perf_historical created in script s_checklist_historical_step05b,
we upload:
    1) the ex-ante portfolio return scenarios 
'''

db_exante_perf_historical = read_csv(r'C:\Projects\Portfolio_Management\examples\Checklist_Historical\Data\Input_Step6\db_exante_perf_historical.csv')
r_w = db_exante_perf_historical.r_w  # ex-ante portfolio return scenarios

# %% 1. Performance expectation
'''
We compute the performance expectation using the scenario-probability mean.
'''

e_r = p_j@r_w  # performance expectation
print('e_r =', f'{(e_r*100).round(2)}%')

# %% 2. Performance negative variance 
'''
We compute the performance (negative) variance using the scenario-probability variance.
'''

v_r = p_j*(r_w - e_r).T@(r_w - e_r)  # performance variance
neg_v_r = -v_r  # negative performance variance
print('neg_v_r =', f'-({(sqrt(abs(neg_v_r))*100).round(1)}%)^2')

# %% 3. Certainty-equivalent 
'''
We first compute the expected utility, with the exponential utility function with parameter
using the invariance rule.
'''

############# input (you can change it) #############
lam = 6  # parameter of exponential utility function
#####################################################

e_ut = p_j@(-exp(-lam*r_w))  # expected utility
'''
Then we calculate the certainty-equivalent by applying the inverse utility to 
the expected utility, in line with the scenario-probability recipe.
 '''
ceq_r = -(1/lam)*log(-e_ut)  # certainty equivalent
print('ceq_r =', f'{(ceq_r*100).round(2)}%')

# %% 4. Quantile (negative VaR)
'''
We compute the smooth quantile q_r{alpha} with:
    confidence:
        1 - alpha = 0.95
    and smoothing parameter:
        h = 0.25 * j^{-0.2}
'''

# First: 
    # we sort the performance scenarios in increasing order to obtain {r_{w,sort}
    # and induce the same sorting on the probabilities to obtain p_sort
    

############## inputs (you can change them) ##############
c = 0.95  # confidence level for quantile and sub-quantile
h = 0.25*(len(r_w)**-0.2)  # smoothing parameter
##########################################################

alpha = 1 - c  # quantile level

r_w_sort = r_w[argsort(r_w)]  # sorted performance scenarios
p_sort = p_j[argsort(r_w)]  # sorted probabilities
'''
Next, we calculate the cumulative sums of the ordered probabilities.
'''
u_sort = append(0, cumsum(p_sort))  # cumulative sums of sorted probabilities

'''
Then we compute the smooth quantile weights and rescale them so they total.
'''
w = diff(normal.cdf(u_sort, alpha, h))  # weights
w = w/sum(w)  # rescaled weights

'''
Using these results, we compute the smooth quantile according to the 
scenario-probability formulation.
'''

q_r = r_w_sort@w  # smooth quantile
print('q_r =', f'{(q_r*100).round(2)}%')

# %% 5. Sub-quantile (negative cVaR) 
'''
We compute the sub-quantile q_{-R}{\alpha} with:
    confidence:
        1 - alpha = 0.95
        
        We use the sorted probabilities p_sort
        and cumulative sums of probabilities u_sort previously computed to 
        calculate the sub-quantile weights, and rescale them so they total 1
'''

w = (1/alpha)*p_sort*(round(u_sort[1:], 5) <= round(alpha, 2))  # weights
w = w/sum(w)  # rescaled weights

'''
Finally, we use the sub-quantile weights and the sorted performance scenarios r_w_sort
to compute sub-quantile  q_{-R}
'''

sub_q_r = r_w_sort@w  # sub-quantile
print('sub_q_r =', f'{(sub_q_r*100).round(2)}%')

# %% Save data
'''
Save the satisfaction measures :
    - performance expectation 
    - performance (negative) variance 
    - certainty-equivalent 
    - quantile and 
    - sub-quantile  
    - as well as the confidence level 
 into database db_quantile_and_satis_historical.
'''

out = DataFrame({'e_r': Series(e_r), 'neg_v_r': Series(neg_v_r), 'ceq_r': Series(ceq_r),
                 'q_r': Series(q_r), 'sub_q_r': Series(sub_q_r), 'c': Series(c)})
out.to_csv(r'C:\Projects\Portfolio_Management\examples\Checklist_Historical\Data\Input_Step7/db_quantile_and_satis_historical.csv', index=False); del out;
